# Stage 10: Interactive Frontend & Intelligence Dashboard

## Overview
Simple, clean web interface for exploring Web3 privacy intelligence with integrated search, local LLM assistance (Ollama), data visualization, and Web3Privacy branded design (via Figma MCP).

## Architecture

### Technology Stack
- **Frontend**: React + TypeScript + Tailwind CSS
- **Search**: MiniSearch (client-side full-text search)
- **LLM**: Ollama (self-hosted, cloud deployment)
- **Data Viz**: D3.js + Chart.js + React Flow
- **Design**: Figma MCP integration for branded components
- **Backend**: FastAPI (Python) for LLM proxy and data serving
- **Deployment**: Docker Compose (frontend + Ollama + API)

### Components

#### 1. Search Engine
```typescript
// Client-side search across all project cards
interface SearchEngine {
  indexProjects(): void;           // Index all JSON files
  indexPersonnel(): void;          // Index personnel cards
  indexOSINT(): void;             // Index OSINT events
  search(query: string): SearchResults;
  filterByCategory(category: string): SearchResults;
  filterByTag(tag: string): SearchResults;
  filterByOpSecScore(min: number, max: number): SearchResults;
}
```

**Searchable Fields:**
- Project names, descriptions, categories
- Team member names, roles, expertise
- Technology tags, development status
- OSINT event types, findings
- Security assessment summaries
- GitHub repositories, links

#### 2. LLM Assistant (Ollama)
```python
# Ollama server running in cloud
# Model: mistral:7b-instruct (good balance of speed/quality)

class IntelligenceAssistant:
    """LLM assistant for answering questions about privacy projects"""

    def __init__(self, ollama_url: str):
        self.client = ollama.Client(ollama_url)
        self.context = self._load_project_context()

    async def answer_question(self, question: str) -> str:
        """Answer questions using project intelligence data"""
        relevant_context = self._retrieve_relevant_projects(question)
        prompt = self._build_prompt(question, relevant_context)
        response = await self.client.generate(
            model="mistral:7b-instruct",
            prompt=prompt,
            context=self.context
        )
        return response

    def sort_projects(self, criteria: str) -> List[Project]:
        """Use LLM to intelligently sort projects"""
        # Examples: "most mature", "best OpSec", "most active development"

    def create_visualization(self, request: str) -> VizConfig:
        """Generate data viz config from natural language"""
        # Example: "show me privacy projects by OpSec score"
```

**LLM Capabilities:**
- Answer questions: "Which projects have the best OpSec?"
- Compare projects: "Compare Aztec and Railgun privacy approaches"
- Summarize findings: "Summarize security issues across all projects"
- Sort and filter: "Show me DeFi projects with active development"
- Generate visualizations: "Create a chart of team sizes"
- Explain concepts: "Explain zero-knowledge proofs in Aztec"

#### 3. Data Visualization Suite

**A. Network Graph**
- Nodes: Projects, people, organizations
- Edges: Team memberships, collaborations, technology shared
- Interactive exploration with zoom/pan
- Powered by React Flow

**B. OpSec Dashboard**
- Bar chart: Projects ranked by OpSec score
- Heatmap: Security finding severity by project
- Timeline: Security events over time

**C. Technology Landscape**
- Bubble chart: Project categories sized by team size
- Tech stack visualization: Common technologies
- Development activity: GitHub commits timeline

**D. Team Network**
- Force-directed graph: Personnel connections
- LinkedIn integration: Professional backgrounds
- Expertise clustering: Skills and domains

**E. OSINT Event Explorer**
- Timeline: All OSINT events chronologically
- Filter by type: DNS, SSL, Email, Social, Threat Intel
- Drill-down: Click event â†’ see full details

#### 4. Web3Privacy Branded UI (Figma MCP)

**Design System Integration:**
```python
# Use Figma MCP to extract design tokens
from figma_mcp import FigmaClient

figma = FigmaClient(token=os.getenv("FIGMA_TOKEN"))

# Extract Web3Privacy design system
design_tokens = figma.get_design_tokens(
    file_id="WEB3PRIVACY_FILE_ID",
    components=["colors", "typography", "spacing", "components"]
)

# Generate Tailwind config
tailwind_config = generate_tailwind_config(design_tokens)

# Export React components
components = figma.export_components([
    "Header", "ProjectCard", "SearchBar", "NavigationMenu",
    "Footer", "DataVizContainer", "LLMChatInterface"
])
```

**Branded Elements:**
- Color palette: Web3Privacy brand colors
- Typography: Brand fonts and hierarchy
- Logo placement: Header, footer, loading screens
- Component library: Cards, buttons, inputs matching brand
- Report templates: Branded PDF export

## User Interface

### Main Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web3Privacy Intelligence Dashboard          [Profile]  â”‚
â”‚  Ethereum Privacy Solutions Report                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [Search: projects, people, tech, findings...]  [Filter]â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              â”‚                                           â”‚
â”‚  Categories  â”‚  Project Cards (Grid View)               â”‚
â”‚              â”‚                                           â”‚
â”‚  â–¡ DeFi      â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                â”‚
â”‚  â–¡ Tools     â”‚  â”‚Aztecâ”‚ â”‚HOPR â”‚ â”‚Rail â”‚                â”‚
â”‚  â–¡ R&D       â”‚  â”‚ 95  â”‚ â”‚ 82  â”‚ â”‚ 88  â”‚                â”‚
â”‚  â–¡ Social    â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                â”‚
â”‚              â”‚                                           â”‚
â”‚  OpSec Score â”‚  [Show All 29 Projects]                  â”‚
â”‚  [0â”€â”€â”€â”€â–ˆâ”€â”€100]â”‚                                          â”‚
â”‚              â”‚                                           â”‚
â”‚  Status      â”‚  Data Visualizations                     â”‚
â”‚  â–¡ Active    â”‚  [Network Graph] [OpSec Chart]           â”‚
â”‚  â–¡ Testnet   â”‚  [Team Network]  [Tech Landscape]        â”‚
â”‚              â”‚                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                          â”‚
â”‚  ğŸ’¬ Ask the LLM Assistant                               â”‚
â”‚  "Which projects have the best privacy guarantees?"     â”‚
â”‚  [Send]                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Detail View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â† Back to Dashboard                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [Logo]  AZTEC                               OpSec: 95  â”‚
â”‚          Programmable privacy for Ethereum               â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚Overview â”‚ Team    â”‚ OSINT   â”‚ Securityâ”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                          â”‚
â”‚  ğŸ“Š Key Metrics                                         â”‚
â”‚  â€¢ Subdomains: 64    â€¢ Team Size: 12                    â”‚
â”‚  â€¢ IP Addresses: 55  â€¢ GitHub Stars: 3.2k               â”‚
â”‚  â€¢ OSINT Events: 132 â€¢ Active Development: âœ…           â”‚
â”‚                                                          â”‚
â”‚  ğŸ‘¥ Team Members                                        â”‚
â”‚  [Zac Williamson] [Joe Andrews] [+10 more]              â”‚
â”‚                                                          â”‚
â”‚  ğŸ¥ Explainer Video                                     â”‚
â”‚  [â–¶ Watch Project Overview (2:34)]                      â”‚
â”‚                                                          â”‚
â”‚  ğŸ“‚ Data Exports                                        â”‚
â”‚  [JSON] [CSV] [PDF Report]                              â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Implementation Structure

```
frontend/
â”œâ”€â”€ public/
â”‚   â””â”€â”€ web3privacy-branding/        # Exported from Figma
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchBar.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchResults.tsx
â”‚   â”‚   â”‚   â””â”€â”€ FilterPanel.tsx
â”‚   â”‚   â”œâ”€â”€ projects/
â”‚   â”‚   â”‚   â”œâ”€â”€ ProjectCard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProjectDetail.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ProjectGrid.tsx
â”‚   â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”‚   â”œâ”€â”€ NetworkGraph.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ OpSecChart.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TeamNetwork.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TechLandscape.tsx
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ QuestionSuggestions.tsx
â”‚   â”‚   â”‚   â””â”€â”€ LLMResponse.tsx
â”‚   â”‚   â””â”€â”€ layout/
â”‚   â”‚       â”œâ”€â”€ Header.tsx
â”‚   â”‚       â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚       â””â”€â”€ Footer.tsx
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ search.ts              # MiniSearch integration
â”‚   â”‚   â”œâ”€â”€ ollama.ts              # LLM API client
â”‚   â”‚   â”œâ”€â”€ dataLoader.ts          # Load JSON files
â”‚   â”‚   â””â”€â”€ export.ts              # PDF/CSV export
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useSearch.ts
â”‚   â”‚   â”œâ”€â”€ useProjects.ts
â”‚   â”‚   â””â”€â”€ useLLMAssistant.ts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ viz.ts                 # D3.js helpers
â”‚   â”‚   â””â”€â”€ formatting.ts
â”‚   â””â”€â”€ App.tsx
â”œâ”€â”€ tailwind.config.js             # Generated from Figma tokens
â””â”€â”€ package.json

backend/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                    # FastAPI server
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ search.py
â”‚   â”‚   â”œâ”€â”€ llm.py                 # Ollama proxy
â”‚   â”‚   â”œâ”€â”€ projects.py
â”‚   â”‚   â””â”€â”€ export.py
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ ollama_client.py
â”‚       â””â”€â”€ data_service.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt

scripts/automation/
â””â”€â”€ stage10_frontend_builder.py    # Build and deploy frontend
```

## Data Loading Strategy

```typescript
// Efficient data loading for frontend
class DataLoader {
  async loadProjects(): Promise<Project[]> {
    // Load all project JSON files
    const projects = await Promise.all(
      PROJECT_IDS.map(id =>
        fetch(`/data/project-cards/${id}/discovery_data.json`)
          .then(r => r.json())
      )
    );
    return projects;
  }

  async loadPersonnel(): Promise<Personnel[]> {
    // Load all personnel JSON files
    const personnel = [];
    for (const project of projects) {
      const people = await fetch(
        `/data/project-cards/${project.id}/personnel.json`
      ).then(r => r.json());
      personnel.push(...people);
    }
    return personnel;
  }

  async loadOSINTEvents(): Promise<OSINTEvent[]> {
    // Load OSINT data (may be large, use pagination)
    const events = await fetch('/api/osint/events?limit=1000')
      .then(r => r.json());
    return events;
  }
}
```

## Ollama Deployment

```yaml
# docker-compose-frontend.yml
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: privacy-intel-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_MODELS=mistral:7b-instruct
    restart: unless-stopped

  backend:
    build: ./backend
    container_name: privacy-intel-api
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_URL=http://ollama:11434
      - DATA_PATH=/data
    volumes:
      - ./research-data:/data:ro
    depends_on:
      - ollama
    restart: unless-stopped

  frontend:
    build: ./frontend
    container_name: privacy-intel-frontend
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - backend
    restart: unless-stopped

volumes:
  ollama-data:
```

## LLM Prompt Engineering

```python
# System prompt for intelligence assistant
SYSTEM_PROMPT = """You are an expert analyst specializing in Web3 privacy technologies.
You have access to comprehensive intelligence data about Ethereum privacy projects,
including team information, OSINT findings, security assessments, and technical details.

Your role is to:
1. Answer questions accurately using the provided project data
2. Compare and contrast different privacy approaches
3. Identify trends and patterns across projects
4. Explain technical concepts clearly
5. Suggest relevant projects based on user criteria

Always cite specific projects and data points when answering.
If you don't have enough data to answer confidently, say so.

Available data:
- 29 privacy projects with full profiles
- 50-100 team members with work history
- 30,000+ OSINT events
- Security assessments with OpSec scores
- GitHub activity and development metrics
"""

# Example question handling
def build_llm_prompt(question: str, context: List[Project]) -> str:
    return f"""{SYSTEM_PROMPT}

User Question: {question}

Relevant Projects:
{json.dumps([p.to_dict() for p in context], indent=2)}

Please provide a clear, concise answer with specific examples.
"""
```

## Export & Reporting

### PDF Report Generation
```python
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image

class BrandedReportGenerator:
    """Generate PDF reports with Web3Privacy branding"""

    def generate_project_report(self, project: Project) -> bytes:
        # Use Figma-exported templates
        doc = SimpleDocTemplate("report.pdf", pagesize=letter)
        story = []

        # Header with Web3Privacy logo
        story.append(Image("assets/web3privacy-logo.png", width=200, height=50))
        story.append(Spacer(1, 20))

        # Project overview
        story.append(Paragraph(f"<b>{project.name}</b>", self.styles['Title']))
        story.append(Paragraph(project.description, self.styles['Body']))

        # Team section
        story.append(Paragraph("Team", self.styles['Heading']))
        for member in project.team:
            story.append(Paragraph(f"â€¢ {member.name} - {member.role}", self.styles['Body']))

        # Security summary
        story.append(Paragraph("Security Assessment", self.styles['Heading']))
        story.append(Paragraph(f"OpSec Score: {project.opsec_score}/100", self.styles['Body']))

        doc.build(story)
```

## Success Metrics

- âœ… Sub-second search across all 29 projects
- âœ… LLM responds to questions within 3-5 seconds
- âœ… All visualizations render smoothly (60fps)
- âœ… Mobile responsive design
- âœ… Web3Privacy branding throughout
- âœ… Export functionality for all data formats
- âœ… Accessible (WCAG 2.1 AA compliance)

## Development Timeline

1. **Day 1-2**: Setup infrastructure, Figma integration, design tokens
2. **Day 3-4**: Build search engine, data loading, basic UI
3. **Day 5-6**: Integrate Ollama, build LLM chat interface
4. **Day 7-8**: Create data visualizations (network graph, charts)
5. **Day 9-10**: Polish UI, add export functionality, testing
6. **Day 11**: Deploy to production, documentation

## Integration with Master Pipeline

```python
# In master_osint_pipeline.py
async def _stage10_frontend_deployment(self):
    """Stage 10: Build and deploy interactive frontend"""
    self.logger.info("stage10_start", stage="frontend_deployment")

    # 1. Extract Figma design tokens
    from scripts.automation.figma_integration import extract_design_system
    design_tokens = extract_design_system(
        figma_token=os.getenv("FIGMA_TOKEN"),
        file_id=os.getenv("WEB3PRIVACY_FIGMA_FILE")
    )

    # 2. Build frontend
    from scripts.automation.stage10_frontend_builder import FrontendBuilder
    builder = FrontendBuilder(
        data_dir="research-data/project-cards/",
        design_tokens=design_tokens
    )
    await builder.build()

    # 3. Deploy with Docker Compose
    await builder.deploy(
        ollama_model="mistral:7b-instruct",
        port=3000
    )

    self.logger.info("stage10_complete",
                    frontend_url="http://localhost:3000",
                    ollama_status="running")
```

## Privacy & Security

- âœ… No sensitive security data exposed in UI (redacted summaries only)
- âœ… LLM runs locally (no data sent to external services)
- âœ… Read-only data access
- âœ… No user tracking or analytics
- âœ… HTTPS only in production
- âœ… Content Security Policy headers