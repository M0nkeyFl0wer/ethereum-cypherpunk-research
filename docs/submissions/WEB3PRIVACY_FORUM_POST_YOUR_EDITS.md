# ğŸ‰ Comprehensive Research Contribution: 40 Web3 Privacy Projects

**Date:** October 25, 2025
**PR:** [#1997](https://github.com/web3privacy/explorer-data/pull/1997)

---

## TL;DR

Just submitted a large research contribution to the Web3Privacy Explorer. 40 privacy projects now have comprehensive documentation including:

- GitHub code analysis
- Team details
- Security assessments
- Technical deep-dives

**Total contribution:** 265 files, 12,378 lines of analysis

---

## What Was Submitted

### Research Scope: 171 Analyzed â†’ 40 Submitted, 788 More in Pipeline

**This submission represents the first wave of a comprehensive ecosystem analysis:**

**Initial Analysis Pool:**
- **171 projects** analyzed or research attempted in initial deep-dive
- **40 projects** passed quality threshold for submission (had sufficient verified data)
- **131 projects** had incomplete or insufficient data for submission

**Research Pipeline:**
- **788 projects** in research-required/ folder awaiting analysis
  - 705 from Web3Privacy Explorer database
  - 48 verified from original archive
  - 35 privacy ecosystem projects (funders, infrastructure, tools)

**Total ecosystem coverage: 959 Web3 privacy projects** (171 analyzed + 788 pipeline)

This PR includes the 40 projects where we found enough information to meet our quality standards through multi-source verification. The methodology that worked for these 40 will now be applied to the remaining 919 projects.

**See examples of research depth:**
- ğŸ“Š [Cake Wallet CODE_REVIEW.md](https://github.com/web3privacy/explorer-data/blob/main/src/projects/cake-wallet/reports/CODE_REVIEW.md) (160 lines - GitHub analysis)
- ğŸ•µï¸ [Mysterium Network OSINT data](https://github.com/M0nkeyFl0wer/ethereum-cypherpunk-research/blob/master/infrastructure/mysterium-network/analysis/osint_data.json) (2,212 lines - infrastructure & team OPSEC)
- â›“ï¸ [Tornado Cash smart contracts](https://github.com/M0nkeyFl0wer/ethereum-cypherpunk-research/blob/master/infrastructure/tornado-cash/analysis/smart_contracts.json) (on-chain data)

### What Each Submitted Project Includes

ğŸ“Š **CODE_REVIEW.md** - Repository analysis (stars, forks, contributors, commit activity, languages)
ğŸ‘¥ **TEAM.md** - Verified leadership information and organization structure
ğŸ”’ **SECURITY.md** - Security features, audit status, privacy mechanisms
âš™ï¸ **TECHNICAL.md** - Technology stack, architecture, capabilities

### File Structure Example

```
web3privacy/explorer-data/src/projects/cake-wallet/
â”œâ”€â”€ index.yaml              â† Basic metadata + links to reports
â”œâ”€â”€ logo.png                â† Project logo
â”œâ”€â”€ README.md               â† Project overview
â”œâ”€â”€ project_metadata.json   â† Aggregated data
â””â”€â”€ reports/
    â”œâ”€â”€ CODE_REVIEW.md      â† 160 lines of GitHub analysis
    â”œâ”€â”€ TEAM.md             â† 98 lines of team info
    â”œâ”€â”€ SECURITY.md         â† 117 lines of security analysis
    â””â”€â”€ TECHNICAL.md        â† 172 lines of tech details
```

---

## Research Methodology

This research follows a systematic, multi-phase approach based on best available information:

### Information Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1: BROAD SEARCH                        â”‚
â”‚  Automated discovery across official sources (parallel agents)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Website    â”‚   GitHub     â”‚  Social      â”‚   News/Blog     â”‚
â”‚   Scraping   â”‚   API        â”‚  Media       â”‚   Aggregators   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  verified_data  â”‚
                    â”‚  (confidence    â”‚
                    â”‚   scores 0-1)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 2: DEEP DIVES                          â”‚
â”‚       Specialized analysis with domain-specific tools           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub     â”‚   OSINT      â”‚  On-Chain    â”‚   Smart         â”‚
â”‚   Analysis   â”‚   Tools      â”‚  Analysis    â”‚   Contract      â”‚
â”‚   (commits,  â”‚ (Spiderfoot, â”‚  (APIs,      â”‚   Review        â”‚
â”‚   languages) â”‚  OPSEC)      â”‚  explorers)  â”‚  (Solidity)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  analysis/      â”‚
                    â”‚  (JSON files    â”‚
                    â”‚   with data)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PHASE 3: REPORT GENERATION                       â”‚
â”‚    Clean markdown reports (internal methodology removed)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CODE_      â”‚   TEAM.md    â”‚  SECURITY.md â”‚   TECHNICAL.md  â”‚
â”‚   REVIEW.md  â”‚              â”‚              â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Web3Privacy Explorer â”‚
                  â”‚  (Public Database)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Four-Layer Data Architecture

Our research maintains a strict separation between internal methodology and public presentation:

### Layer 1: Internal Research (`sources/`)
- **verified_data.json** - Raw data with confidence scores (0.0-1.0)
- Multi-source verification metadata
- Research methodology tracking
- **Never publicly exposed**

### Layer 2: Analysis Data (`analysis/`)
- **github_analysis.json** - Repository metrics, languages, activity
- **smart_contracts.json** - Contract addresses, deployment info
- **osint_data.json** - Infrastructure and team OSINT research
- **oso_data.json** - Open Source Observer data
- **Intermediate processing layer**

### Layer 3: Public Reports (`reports/`)
- **CODE_REVIEW.md** - Clean GitHub analysis
- **TEAM.md** - Verified team information
- **SECURITY.md** - Security features and audits
- **TECHNICAL.md** - Technology and capabilities
- **Clean, professional markdown - no internal methodology exposed**

### Layer 4: Export Metadata (root)
- **project_metadata.json** - Aggregated data for APIs
- **index.yaml** - Web3Privacy Explorer format
- **README.md** - Project landing page

---

## Research Quality Standards

Every data point follows our "constitutional research" methodology:

### âœ… No Placeholders or Fabrication

**Best available information with honest limitations**

- No placeholder text like "Team of 5-10 developers"
- No estimates like "Approximately $2M in funding"
- If we don't know it, we document it as a gap
- **Note:** Sources themselves may contain errors, tools can hallucinate, experimental pipelines may introduce issues - we ask the community to submit corrections via PRs/issues

### âœ… Multi-Source Verification

**Critical facts require 2+ independent sources**

```
Founder: Vikrant Sharma
â”œâ”€â”€ Source 1: Official interview (changenow.io)
â”œâ”€â”€ Source 2: LinkedIn profile
â””â”€â”€ Confidence: 0.95
```

### âœ… Confidence Scoring (0.0 - 1.0)

- **1.0** - Official source (website, GitHub)
- **0.9-0.95** - Secondary source (verified interview, LinkedIn)
- **0.7-0.85** - Tertiary source (news, community)
- **< 0.7** - Not included in public reports

### âœ… Honest Gap Reporting

We explicitly document what we DON'T know.

This prevents others from wasting time on failed research approaches.

---

## Decentralized Agent Swarms (Tool Orchestration)

To scale this methodology across 40 projects, we deployed **parallel LLM agents for task coordination**:

### Batch Processing Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            CONTROL AGENT (Task Orchestrator)                â”‚
â”‚  Assigns projects to worker agents, monitors progress       â”‚
â”‚  LLM manages which tools to run, not data generation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼               â–¼               â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent 1 â”‚     â”‚ Agent 2 â”‚     â”‚ Agent 3 â”‚...â”‚ Agent 6 â”‚
â”‚ Batch 1 â”‚     â”‚ Batch 2 â”‚     â”‚ Batch 3 â”‚   â”‚ Batch 6 â”‚
â”‚ 7 proj  â”‚     â”‚ 7 proj  â”‚     â”‚ 7 proj  â”‚   â”‚ 7 proj  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚               â”‚             â”‚
      â–¼               â–¼               â–¼             â–¼
For each project (LLM decides which tools to run):
1. WebSearch official sources â†’ real-time data
2. GitHub API calls â†’ live repo data
3. Python scripts â†’ process/analyze results
4. Generate markdown reports â†’ format output
5. Verify quality â†’ cross-check sources
```

### What LLMs Did vs Didn't Do

**LLMs handle (coordination & transformation layers):**
- Deciding which tools to run (WebSearch, GitHub API, Python scripts)
- Coordinating task sequences (search first, then analyze)
- **Extracting structured data from API responses** âš ï¸ hallucination risk
- **Formatting results into markdown reports** âš ï¸ hallucination risk
- Cross-validating between different data sources

**LLMs DIDN'T do:**
- Generate data from training knowledge
- Make up facts or statistics
- Fill in missing information with guesses

**Where hallucination risk exists:**
- **Coordination layer:** LLM might choose wrong tool or misinterpret task requirements
- **Transformation layer:** LLM might misextract data when parsing API responses or formatting markdown

**Risk mitigation through validation layers:**
- Multi-agent cross-validation (different agents verify same data)
- Confidence scoring on extracted data
- Manual spot-checks of outputs
- Source URLs preserved in internal files for verification

**All actual research data comes from:** Live web searches, API calls, and real-time sources - not LLM training data.

### Parallel Execution Benefits

**Quality assurance:** Each agent runs independent verification using real-time tools, control agent validates outputs before acceptance. Multiple agents working in parallel allows faster processing while maintaining research quality through cross-validation.

---

## Quality Metrics

### By The Numbers

| Metric | Value |
|--------|-------|
| Projects committed | 40 |
| Total research files | 265 |
| Lines of analysis | 12,378 |
| Average confidence | 0.85-0.95 |
| No intentional fabrication | Yes |
| Multi-source verification | 100% |
| Community corrections welcome | Yes |

### Data Quality Breakdown

**Tier 1 (Basic Info):** 100% complete
- Website, GitHub, description, status

**Tier 2 (Detailed Data):** 70-80% complete
- Team information, technology stack, security features

**Tier 3 (Advanced):** 40-60% complete
- Full funding details, complete team rosters, detailed on-chain metrics

### ATTEMPTED Files: Honest Gap Reporting

18 projects have **blockchain_metrics_ATTEMPTED.md** files documenting research that found no data:

- Attempted: Etherscan, DeFiLlama, block explorers
- Result: No verifiable on-chain data found
- Reason: Could be testnet-only, private chains, or insufficient documentation
- **Purpose:** Prevent others from repeating failed approaches

---

## Research Tools & Technology Stack

### Data Collection Tools

- **WebFetch** - Automated website content extraction (real-time data)
- **WebSearch** - Multi-source verification and news discovery (real-time data)
- **GitHub API** - Repository metrics and code analysis (live API calls)
- **Blockchain APIs** - Etherscan, DeFiLlama, custom block explorers (on-chain data)
- **Playwright MCP** - Browser automation for debugging and verification

### Analysis Tools

- **Python scripts** - Custom data processing and analysis
- **Spiderfoot** - OSINT reconnaissance on team members and infrastructure
- **Smart Contract Review** - Solidity analysis, security pattern detection

### Agent Coordination

- **LLM agents** - Used for tool orchestration and task management (NOT for data generation)
- **Important:** LLMs coordinated which tools to run and how to process results
- **Data sources:** All actual research data came from web APIs, searches, and live sources - not LLM training data

### Quality Assurance

- **"Constitutional research" methodology** - No intentional fabrication, best available sources
- **Multi-agent verification** - Cross-checking between agents
- **Confidence scoring** - Automated quality metrics
- **Manual spot-checks** - Random sampling of 5+ projects per batch
- **Community review** - Open to corrections via PRs and issues

---

## What's Next

### Immediate Next Steps

1. **Tag all 40 project repositories on GitHub**
   - Notify project teams that their research is available
   - Encourage them to review and submit corrections/updates
   - Invite them to fill data gaps (team info, funding, on-chain metrics)

2. **Research-required projects (47 remaining)**
   - Work to obtain basic surface-level information (website, repo, description)
   - Many are promising projects but lack public documentation
   - Once basics are found, apply same comprehensive research methodology

3. **Regular updates** as projects evolve
   - New releases, team changes, security audits
   - On-chain metric updates for active protocols
   - Community-submitted corrections and additions

### Projects Awaiting Further Research (47 total)

<details>
<summary>Click to expand list of projects in research-required/ folder</summary>

These projects need basic surface-level information before comprehensive research can begin:

1inch-privacy, aleo, anoma, brave-browser, curve-privacy, curvy, dark-forest, dash, dusk-network, eth2-deposit-cli, farcaster, gitcoin-grants, hinkal, horizen, hurricane-core, inco, keep-network, lens-protocol, maci, mask, metamask-snaps, mina-protocol, night, nighthawk-wallet, nocturne, nuconstruct, nucypher, polygon-hermez, polygon-zero, pse-privacy-scaling-explorations, railway, rarime, ronin, samourai-wallet, snapshot-x, starknet, taceo, token-shielder, zama, zecrey, zkbob, zksync-era, zupass

</details>

**If you're involved with any of these projects** - please submit basic info (website, GitHub, brief description) so we can conduct comprehensive research!

### Long-term Vision: Decentralized Research Infrastructure

The goal is to scale this methodology across the entire Web3 privacy ecosystem through:

1. **Scale to 700+ projects** - Apply this research methodology broadly
2. **Continuous monitoring** - Detect new commits, releases, security advisories
3. **Automated updates** - Generate PRs when significant changes detected
4. **Community-driven** - Multiple contributors using various tools and approaches
5. **Open methodology** - Anyone can apply this research framework with their own infrastructure

### Why Code Review & OPSEC Matter for Privacy Projects

Privacy projects require deeper analysis beyond basic features. Here's why:

**ğŸ” Code Review is Critical for Privacy Claims**

- **Trust verification:** "Privacy-preserving" is a claim that requires code-level validation
- **Implementation quality:** Privacy features in whitepaper â‰  privacy features in production code
- **Active development:** Regular commits indicate ongoing security maintenance
- **Community involvement:** Contributor count and diversity signal decentralization
- **Example:** A mixer claiming "trustless privacy" but with centralized admin keys visible in code

**ğŸ•µï¸ OPSEC Research Protects Users**

- **Infrastructure analysis:** Centralized servers for "decentralized" privacy tools
- **Funding transparency:** Who's backing privacy infrastructure matters for trust
- **Attack surface:** OSINT reveals potential vectors (DNS, hosting, dependencies, team member vulnerabilities)

**These layers are especially important for privacy projects because:**

1. Users trust these tools with sensitive data
2. Privacy failures can have severe real-world consequences
3. Marketing claims often exceed technical reality
4. Decentralization claims need verification
5. Security research requires technical depth

### Why This Matters

**For Projects:**
- Professional, accurate documentation of their work
- Technical validation of privacy claims
- Regular updates as they evolve
- Opportunity to correct errors and fill gaps

**For Users:**
- Comprehensive, up-to-date information
- Technical verification of privacy features
- Honest assessment of limitations and risks
- Verified, multi-source data

**For Researchers:**
- Avoid duplicating failed research
- Build on existing verified work
- Contribute to growing knowledge base
- Technical depth beyond surface-level analysis

---

## Contributing & Feedback

### How to Help

**Project Teams:** Found an error? Have updated information?
- Submit PR to: https://github.com/web3privacy/explorer-data
- Or open issue: Tag @M0nkeyFl0wer

**Researchers:** Want to contribute?
- Use our methodology: https://github.com/M0nkeyFl0wer/ethereum-cypherpunk-research
- Focus on projects in research-required/ folder
- Apply the same quality standards (multi-source verification, no fabrication, honest gaps)

**Community:** Questions or suggestions?
- Reply to this thread
- DM me on the forum
- Open a discussion on GitHub

---

## ğŸ’¡ What Should We Prioritize Next?

I'd love the community's input on next steps:

**Potential priorities:**

1. Tag all 40 projects on GitHub to notify teams?
2. Focus on the 47 research-required projects to get basic info?
3. Deeper OPSEC research on high-profile projects (infrastructure, dependencies)?
4. On-chain analysis for protocols with smart contracts?
5. Automated monitoring for security advisories and major updates?
6. Something else entirely?

**Specific questions:**

- Which projects from the research-required list are most important to the community?
- What additional data layers would be most valuable? (Funding details? Token metrics? Audit history?)
- Should we prioritize breadth (more projects) or depth (more detailed analysis)?
- Any tools or data sources we should integrate?

**Drop your thoughts below!** This is community-driven research - your input shapes the roadmap.

---

## Repository Links

**Main Research Repo:**
https://github.com/M0nkeyFl0wer/ethereum-cypherpunk-research

**PR to Web3Privacy Explorer:**
https://github.com/web3privacy/explorer-data/pull/1997

**Forked Explorer (with all files):**
https://github.com/M0nkeyFl0wer/explorer-data

---

## Acknowledgments

Huge thanks to:

- **Web3Privacy team** for maintaining this essential database
- **All project teams** for building privacy-preserving infrastructure
- **Web3Privacy community** for feedback and support
- **Future contributors** who will help scale this research methodology

---

## License

All research data submitted under **Open Database License (ODbL)** to match Web3Privacy Explorer licensing.

---

## Important Disclaimers

**This research is based on publicly available information and best-effort analysis.** Limitations include:

- **Source reliability:** We rely on official sources, but those sources themselves may contain errors or outdated information
- **Tool limitations:** Research tools (APIs, OSINT tools, browser automation) can miss data, timeout, or introduce errors
- **LLM coordination & transformation risks:** While research data comes from live sources (not LLM training data), LLMs can introduce errors in:
  - **Coordination layer:** Choosing wrong tools or misinterpreting tasks
  - **Transformation layer:** Misextracting data from API responses or incorrectly formatting outputs
  - Validation layers (multi-agent verification, manual spot-checks) mitigate but don't eliminate this risk
- **Experimental pipeline:** This methodology uses experimental agent swarms and novel approaches - bugs may exist
- **Point-in-time data:** Information accurate as of October 2025 - projects evolve rapidly
- **Coverage gaps:** Some areas (funding, complete team rosters, on-chain metrics) have limited public data

**We actively encourage corrections!** If you spot errors, outdated info, or have additional data:

- Submit a PR to the Web3Privacy Explorer
- Open an issue on our research repo
- Comment on this thread

This is a living dataset that improves through community collaboration.

---

**Questions? Comments? Let's discuss below!** ğŸ‘‡

I'm happy to explain the methodology in more detail, share specific examples, or discuss how we can scale this to cover more projects.

ğŸ”’ Privacy is a fundamental right.

---

*Research conducted October 2025*
*Contributor: @M0nkeyFl0wer*
